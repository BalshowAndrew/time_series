# Вебинар по теме "Модели ARMA"

Цель исследования модели - это понять, какая это модель

Процесс исследования:
- делаем предположение (гипотезу), какая это может быть модель;
- строим модель;
- делаем предсказание временного ряда;
- вычитаем из первоначального ряда предсказанные значения;
- если график остатков стационарен, то можно анализ окончить;
- если график остатков не стационарен, то мы либо что-то не учли в модели (тренд, сезонность...), либо неправильно предсказали саму модель;

Будем представлять временной ряд $y_t$ в виде

$y_t = T + S + E$

где T - тренд, S - сезонная компонента, E - ошибка прогноза

## Белый шум и случайные блуждания

### Белый шум

$y_t = E$

Значениями этого временного ряда являются случайные величины

Сгенерируем этот временной ряд:

```python

randser = np.random.normal(size=1000)

```

### Случайные блуждания (Random Walk)

$y_t = y_{t-1} + \epsilon_{t}$

где $\epsilon_{t}$ - белый шум (знаяения берутся из нормального распределения)

Особенность случайного блуждания в том, что он не стационарен, т.е. его свойства меняются со временем и предсказать его невозможно. Каждое следующее значение этого временного ряда рвно предыдущему плюс слуяайный шум.

#### Сгенерируем Random Walk

**Первый вариант** - с использованием цикла:

```python

n_samples = 1000

eps = np.random.normal(size=n_samples)
x = [0 + eps[0]]
for i in range(1, n_samples):
    x.append(x[i-1] + eps[i])

```
**Второй вариант** - с использованием функции **np.cumsum()**

```python

# создаем эпсилон:
x = np.random.normal(size=1000)
# применяем куммулятивную сумму:
x = np.cumsum(x)

```
В этом варианте каждое следующее значение равно сумме предыдущего и случайной величины (что нам собственно и нужно).

#### Проверим, является ли наш временной ряд рядом случайных блужданий

Если временной ряд является рядом случайных блужданий, в результате проведения по отношению к нему операции обратной коммулятивной сумме мы должны получить белый шум. Эта операция называется дифференцированием.

```python

np.diff(x) # ряд попарных разностей с лагом = 1

```


## Авторегрессионная модель (AR(p))

Авторегрессионная модель — модель временных рядов, в которой значения временного ряда в данный момент линейно зависят от предыдущих значений этого же ряда. Авторегрессионный процесс порядка p (AR(p)-процесс) определяется следующим образом

$y_t = c + \sum_{i=1}^P a_i y_{t-i} + \epsilon_t$

где $\epsilon_t$ - белый шум

### Сгенерируем AR

Сделаем симуляцию процесса AR(1) и посмотрим, сумеет ли модель AR правильно подобрать коэффициенты

```python

np.random.seed(1)
n_samples = int(1000)
a = 0.5
x = w = np.random.normal(size=n_sapmles)

for t in range(n_samples):
    x[t] = a*x[t-1] + w[t]

```

### Обучим модель авторегрессии

Для этого будем использовать класс [AutoReg](https://www.statsmodels.org/stable/generated/statsmodels.tsa.ar_model.AutoReg.html) библиотеки **statsmodels**

[Ссылка на блокнот Autoregressions](https://www.statsmodels.org/stable/examples/notebooks/generated/autoregressions.html)


```python

from statsmodels.tsa.ar_model import AutoReg

mdl = AutoReg(x, lags = 1).fit()

print(mdl.summary())

```

```bash

AutoReg Model Results                             
==============================================================================
Dep. Variable:                      y   No. Observations:                 1000
Model:                     AutoReg(1)   Log Likelihood               -1397.248
Method:               Conditional MLE   S.D. of innovations              0.980
Date:                Mon, 20 May 2024   AIC                           2800.495
Time:                        20:01:20   BIC                           2815.216
Sample:                             1   HQIC                          2806.090
                                 1000                                         
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.0389      0.031      1.252      0.211      -0.022       0.100
y.L1           0.4783      0.028     17.234      0.000       0.424       0.533
                                    Roots                                    
=============================================================================
                  Real          Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            2.0906           +0.0000j            2.0906            0.0000
-----------------------------------------------------------------------------
``` 

### Как нам понять: правильно ли мы оценили эту модель?

Для этого можно посмотреть на **ряд остатков**. Этот ряд равен разности исходного и предсказанного рядов. Если модель угадана правильно, то в результате мы должны получить случайную ошибку (т.е. полученный временной ряд должен быть стационарным)

```python

mdl.resid

```
















